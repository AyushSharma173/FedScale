{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "(04-28) 18:20:19 INFO     [aggregator.py:44] Job args Namespace(experiment_mode='simulation', use_cuda=False, cuda_device=None, device_conf_file='', ps_port=29500, executor_configs='127.0.0.1:[1]', connection_timeout=60, job_name='demo_job', time_stamp='ts1', data_set='cifar10', model='resnet18', sample_mode='random', gradient_policy='fedavg', task='cv', cfg_file=None, data_dir='./data', local_steps=1, batch_size=32, num_participants=4, rounds=10, eval_interval=1, overcommitment=1.3, learning_rate=0.01, decay_round=5, decay_factor=0.5, min_learning_rate=1e-05, wandb_token='', save_checkpoint=False, log_path='./logs', filter_less=0, filter_more=1, device_avail_file=None, client_timeout=10, client_retry_interval=1, client_retry_max=3, this_rank=0, num_executors=1, ps_ip='127.0.0.1', engine='pytorch', model_zoo='fedscale-torch-zoo', num_class=10, data_map_file=None, memory_capacity=0, test_bsz=32)\n",
      "(04-28) 18:20:19 INFO     [aggregator.py:164] Initiating control plane communication ...\n",
      "(04-28) 18:20:19 INFO     [aggregator.py:187] %%%%%%%%%% Opening aggregator server using port [::]:29500 %%%%%%%%%%\n",
      "(04-28) 18:20:19 INFO     [fllibs.py:97] Initializing the model ...\n",
      "(04-28) 18:20:19 INFO     [aggregator.py:967] Start monitoring events ...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from argparse import Namespace\n",
    "\n",
    "import fedscale.cloud.config_parser as parser\n",
    "from fedscale.cloud.aggregation.aggregator import Aggregator\n",
    "import fedscale.cloud.commons as commons\n",
    "\n",
    "# 1) Clear out any stray argv\n",
    "sys.argv = ['']\n",
    "\n",
    "# 2) Define every field Aggregator expects:\n",
    "parser.args = Namespace(\n",
    "    # ———— mode & devices ————\n",
    "    experiment_mode=commons.SIMULATION_MODE,  # or commons.DEPLOYMENT_MODE\n",
    "    use_cuda=False,                           # we're on CPU\n",
    "    cuda_device=None,                         # GPU index if use_cuda=True\n",
    "    device_conf_file=\"\",                    # path to client‐profile .pkl, or None\n",
    "\n",
    "    # ———— gRPC/server config ————\n",
    "    ps_port=29500,                            # port aggregator listens on\n",
    "    executor_configs=\"127.0.0.1:[1]\",         # \"ip:[gpu1,gpu2,…]=ip2:[…]\" for sim\n",
    "    connection_timeout=60,                    # seconds to wait for a client ping\n",
    "\n",
    "    # ———— FL hyperparameters ————\n",
    "    job_name=\"demo_job\",                      # logging / wandb project name\n",
    "    time_stamp=\"ts1\",                         # unique run identifier (used in logDir)\n",
    "    data_set=\"cifar10\",                       # name of your dataset\n",
    "    model=\"resnet18\",                         # model identifier\n",
    "    sample_mode=\"random\",                     # \"random\" or \"oort\"\n",
    "    gradient_policy=\"fedavg\",                 # e.g. \"fedavg\", \"q-fedavg\", …\n",
    "    task=\"cv\",                                # \"cv\" or \"detection\"\n",
    "    cfg_file=None,                            # only needed if task=\"detection\"\n",
    "    data_dir=\"./data\",                        # where your data lives (for detection)\n",
    "\n",
    "    # client‐side training config\n",
    "    local_steps=1,                            # number of local mini‐batches per client\n",
    "    batch_size=32,                            # batch size on each client\n",
    "\n",
    "    # federation rounds\n",
    "    num_participants=4,                       # clients sampled per round\n",
    "    rounds=10,                                # total federated rounds\n",
    "    eval_interval=1,                          # do testing every N rounds\n",
    "    overcommitment=1.3,                       # select_num * overcommitment\n",
    "    learning_rate=0.01,                       # initial LR for your clients\n",
    "    decay_round=5,                            # every N rounds, decay LR\n",
    "    decay_factor=0.5,                         # multiply LR by this\n",
    "    min_learning_rate=1e-5,                   # floor for LR decay\n",
    "\n",
    "    # ———— logging & checkpointing ————\n",
    "    wandb_token=\"\",                           # \"\" to disable wandb\n",
    "    save_checkpoint=False,                    # whether to np.save() each round\n",
    "    log_path=\"./logs\",\n",
    "    filter_less=0,\n",
    "    filter_more=1,\n",
    "    device_avail_file=None,\n",
    "    client_timeout=10,\n",
    "    client_retry_interval=1,\n",
    "    client_retry_max=3,\n",
    "    this_rank=0,\n",
    "    num_executors=1,\n",
    "    ps_ip=\"127.0.0.1\",\n",
    "    engine=commons.PYTORCH,\n",
    "    model_zoo=\"fedscale-torch-zoo\",\n",
    "    num_class=10,\n",
    "    data_map_file=None,\n",
    "    memory_capacity=0,\n",
    "    test_bsz=32,\n",
    "    \n",
    ")\n",
    "\n",
    "# 3) Now start it:\n",
    "Demo_Aggregator = Aggregator(parser.args)\n",
    "Demo_Aggregator.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
